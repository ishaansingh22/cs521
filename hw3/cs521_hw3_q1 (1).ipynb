{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PThPLvemCTHs"
   },
   "outputs": [],
   "source": [
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qWRQzdCqGlb-",
    "outputId": "59c61684-3cd8-44a7-b90d-845fe186e6c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.80MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 61.4kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:06<00:00, 238kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.50MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorboardX\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = False\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 64\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "## Dataloaders\n",
    "train_dataset = datasets.MNIST('mnist_data/', train=True, download=True, transform=transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    "))\n",
    "test_dataset = datasets.MNIST('mnist_data/', train=False, download=True, transform=transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    "))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2nQii2fyJsU6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V8Uqa-JpCVqb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tb_Zky6aGutn"
   },
   "outputs": [],
   "source": [
    "# Define the network\n",
    "class SimpleFCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleFCNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 50)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iN3R7wPWZKgs"
   },
   "outputs": [],
   "source": [
    "def propagate_bounds(x, weight, bias):\n",
    "    lower, upper = x[0], x[1]\n",
    "    lower = lower.view(lower.size(0), -1)\n",
    "    upper = upper.view(upper.size(0), -1)\n",
    "    center = (lower + upper) / 2\n",
    "    deviation = (upper - lower) / 2\n",
    "    center = torch.matmul(center, weight.T) + bias\n",
    "    deviation = torch.matmul(deviation, torch.abs(weight.T))\n",
    "    lower_bound = center - deviation\n",
    "    upper_bound = center + deviation\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "def relu_bounds(lower, upper):\n",
    "    \"\"\"Propagate bounds through a ReLU layer.\"\"\"\n",
    "    return F.relu(lower), F.relu(upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CTBdOpvQHYiO"
   },
   "outputs": [],
   "source": [
    "def ibp_loss(logits, true_labels, logits_robust, kappa):\n",
    "    nominal_loss = F.cross_entropy(logits, true_labels)\n",
    "    robust_loss = F.cross_entropy(logits_robust, true_labels)\n",
    "    return kappa * nominal_loss + (1 - kappa) * robust_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0ZcVFlryHY5R"
   },
   "outputs": [],
   "source": [
    "def ibp_forward(model, x, eps):\n",
    "    lower_bound = x - eps\n",
    "    upper_bound = x + eps\n",
    "    l1, u1 = propagate_bounds((lower_bound, upper_bound), model.fc1.weight, model.fc1.bias)\n",
    "    l1, u1 = relu_bounds(l1, u1)\n",
    "    l2, u2 = propagate_bounds((l1, u1), model.fc2.weight, model.fc2.bias)\n",
    "    l2, u2 = relu_bounds(l2, u2)\n",
    "    l3, u3 = propagate_bounds((l2, u2), model.fc3.weight, model.fc3.bias)\n",
    "    return l3, u3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MDGDSPIsHanY"
   },
   "outputs": [],
   "source": [
    "def schedule_kappa(step, total_steps):\n",
    "    initial_kappa = 1.0\n",
    "    final_kappa = 0.5\n",
    "    return max(final_kappa, initial_kappa - (initial_kappa - final_kappa) * (step / total_steps))\n",
    "\n",
    "def schedule_epsilon(step, total_steps, target_epsilon=0.1):\n",
    "    return min(target_epsilon, target_epsilon * (step / total_steps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cRViMwLrHcuM"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, total_steps, eps_target=0.1):\n",
    "    model.train()\n",
    "    current_step = 0\n",
    "\n",
    "    while current_step < total_steps:\n",
    "        for images, labels in train_loader:\n",
    "            if current_step >= total_steps:\n",
    "                break\n",
    "            logits = model(images)\n",
    "            lower_logits, upper_logits = ibp_forward(model, images, eps_target)\n",
    "            logits_robust = (lower_logits + upper_logits) / 2  # Middle point approximation\n",
    "            kappa = schedule_kappa(current_step, total_steps)\n",
    "            epsilon_train = schedule_epsilon(current_step, total_steps, eps_target)\n",
    "            loss = ibp_loss(logits, labels, logits_robust, kappa)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if current_step % 100 == 0:\n",
    "                print(f\"Step [{current_step}/{total_steps}], Loss: {loss.item()}, kappa: {kappa:.2f}, epsilon_train: {epsilon_train:.2f}\")\n",
    "\n",
    "            current_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "92gZV_BCaV_c"
   },
   "outputs": [],
   "source": [
    "def compute_worst_case_logits(lower_logits, upper_logits, true_labels):\n",
    "    worst_case_logits = upper_logits.clone()\n",
    "\n",
    "    for i in range(len(true_labels)):\n",
    "        worst_case_logits[i, true_labels[i]] = lower_logits[i, true_labels[i]]\n",
    "\n",
    "    return worst_case_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zfgfa34BHgKf"
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader, epsilon):\n",
    "    model.eval()\n",
    "    correct_nominal = 0\n",
    "    correct_robust = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            logits = model(images)\n",
    "            _, pred = logits.max(1)\n",
    "            correct_nominal += (pred == labels).sum().item()\n",
    "            lower_logits, upper_logits = ibp_forward(model, images, epsilon)\n",
    "            logits_robust = compute_worst_case_logits(lower_logits, upper_logits, labels)\n",
    "            _, pred_robust = logits_robust.max(1)\n",
    "            correct_robust += (pred_robust == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    nominal_accuracy = correct_nominal / total\n",
    "    robust_accuracy = correct_robust / total\n",
    "    print(f\"Nominal Accuracy: {nominal_accuracy*100:.2f}%, Robust Accuracy: {robust_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "IdifJi-5bZEY"
   },
   "outputs": [],
   "source": [
    "def pgd_attack(model, images, labels, epsilon, alpha=0.01, iters=40):\n",
    "    adv_images = images.clone().detach().requires_grad_(True)\n",
    "    for i in range(iters):\n",
    "        outputs = model(adv_images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        adv_images = adv_images + alpha * adv_images.grad.sign()\n",
    "        eta = torch.clamp(adv_images - images, min=-epsilon, max=epsilon)\n",
    "        adv_images = torch.clamp(images + eta, min=0, max=1).detach_().requires_grad_(True)\n",
    "    return adv_images\n",
    "\n",
    "def test_with_pgd(model, test_loader, epsilon, alpha=0.01, iters=40):\n",
    "    model.eval()\n",
    "    correct_nominal = 0\n",
    "    correct_robust = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        with torch.no_grad():\n",
    "            logits = model(images)\n",
    "            _, pred = logits.max(1)\n",
    "            correct_nominal += (pred == labels).sum().item()\n",
    "        adv_images = pgd_attack(model, images, labels, epsilon, alpha, iters)\n",
    "        with torch.no_grad():\n",
    "            adv_logits = model(adv_images)\n",
    "            _, pred_robust = adv_logits.max(1)\n",
    "            correct_robust += (pred_robust == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    nominal_accuracy = correct_nominal / total\n",
    "    robust_accuracy = correct_robust / total\n",
    "    print(f\"Nominal Accuracy: {nominal_accuracy*100:.2f}%, Robust Accuracy: {robust_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IolQQqHkgsXl"
   },
   "outputs": [],
   "source": [
    "def hybrid_loss(logits, true_labels, logits_robust, logits_pgd, kappa, lambda_reg=0.5):\n",
    "    nominal_loss = F.cross_entropy(logits, true_labels)\n",
    "    robust_loss_ibp = F.cross_entropy(logits_robust, true_labels)\n",
    "    robust_loss_pgd = F.cross_entropy(logits_pgd, true_labels)\n",
    "    combined_loss = kappa * nominal_loss + (1 - kappa) * (lambda_reg * robust_loss_ibp + (1 - lambda_reg) * robust_loss_pgd)\n",
    "    return combined_loss\n",
    "\n",
    "def train_with_pgd_and_ibp(model, optimizer, train_loader, total_steps, eps_target=0.1, pgd_alpha=0.01, pgd_iters=10):\n",
    "    model.train()\n",
    "    current_step = 0\n",
    "\n",
    "    while current_step < total_steps:\n",
    "        for images, labels in train_loader:\n",
    "            if current_step >= total_steps:\n",
    "                break\n",
    "            logits = model(images)\n",
    "            lower_logits, upper_logits = ibp_forward(model, images, eps_target)\n",
    "            logits_robust = (lower_logits + upper_logits) / 2\n",
    "            adv_images = pgd_attack(model, images, labels, epsilon=eps_target, alpha=pgd_alpha, iters=pgd_iters)\n",
    "            logits_pgd = model(adv_images)\n",
    "            kappa = schedule_kappa(current_step, total_steps)\n",
    "            epsilon_train = schedule_epsilon(current_step, total_steps, eps_target)\n",
    "            loss = hybrid_loss(logits, labels, logits_robust, logits_pgd, kappa)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if current_step % 100 == 0:\n",
    "                print(f\"Step [{current_step}/{total_steps}], Loss: {loss.item():.4f}, kappa: {kappa:.2f}, epsilon_train: {epsilon_train:.2f}\")\n",
    "\n",
    "            current_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfw1IGIYmII_",
    "outputId": "7aaeae96-3534-4d03-ac18-0b5636bb4ea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/10000], Loss: 2.3178, kappa: 1.00, epsilon_train: 0.00\n",
      "Step [100/10000], Loss: 0.5459, kappa: 0.99, epsilon_train: 0.00\n",
      "Step [200/10000], Loss: 0.4860, kappa: 0.99, epsilon_train: 0.00\n",
      "Step [300/10000], Loss: 0.3766, kappa: 0.98, epsilon_train: 0.00\n",
      "Step [400/10000], Loss: 0.2463, kappa: 0.98, epsilon_train: 0.00\n",
      "Step [500/10000], Loss: 0.2111, kappa: 0.97, epsilon_train: 0.01\n",
      "Step [600/10000], Loss: 0.3070, kappa: 0.97, epsilon_train: 0.01\n",
      "Step [700/10000], Loss: 0.4215, kappa: 0.96, epsilon_train: 0.01\n",
      "Step [800/10000], Loss: 0.2074, kappa: 0.96, epsilon_train: 0.01\n",
      "Step [900/10000], Loss: 0.4599, kappa: 0.95, epsilon_train: 0.01\n",
      "Step [1000/10000], Loss: 0.3905, kappa: 0.95, epsilon_train: 0.01\n",
      "Step [1100/10000], Loss: 0.3331, kappa: 0.94, epsilon_train: 0.01\n",
      "Step [1200/10000], Loss: 0.2277, kappa: 0.94, epsilon_train: 0.01\n",
      "Step [1300/10000], Loss: 0.2856, kappa: 0.94, epsilon_train: 0.01\n",
      "Step [1400/10000], Loss: 0.2572, kappa: 0.93, epsilon_train: 0.01\n",
      "Step [1500/10000], Loss: 0.1752, kappa: 0.93, epsilon_train: 0.01\n",
      "Step [1600/10000], Loss: 0.1699, kappa: 0.92, epsilon_train: 0.02\n",
      "Step [1700/10000], Loss: 0.1585, kappa: 0.92, epsilon_train: 0.02\n",
      "Step [1800/10000], Loss: 0.2365, kappa: 0.91, epsilon_train: 0.02\n",
      "Step [1900/10000], Loss: 0.2844, kappa: 0.91, epsilon_train: 0.02\n",
      "Step [2000/10000], Loss: 0.1431, kappa: 0.90, epsilon_train: 0.02\n",
      "Step [2100/10000], Loss: 0.1804, kappa: 0.90, epsilon_train: 0.02\n",
      "Step [2200/10000], Loss: 0.2196, kappa: 0.89, epsilon_train: 0.02\n",
      "Step [2300/10000], Loss: 0.3457, kappa: 0.89, epsilon_train: 0.02\n",
      "Step [2400/10000], Loss: 0.1049, kappa: 0.88, epsilon_train: 0.02\n",
      "Step [2500/10000], Loss: 0.1818, kappa: 0.88, epsilon_train: 0.03\n",
      "Step [2600/10000], Loss: 0.1804, kappa: 0.87, epsilon_train: 0.03\n",
      "Step [2700/10000], Loss: 0.2176, kappa: 0.86, epsilon_train: 0.03\n",
      "Step [2800/10000], Loss: 0.1948, kappa: 0.86, epsilon_train: 0.03\n",
      "Step [2900/10000], Loss: 0.1986, kappa: 0.85, epsilon_train: 0.03\n",
      "Step [3000/10000], Loss: 0.1360, kappa: 0.85, epsilon_train: 0.03\n",
      "Step [3100/10000], Loss: 0.2270, kappa: 0.84, epsilon_train: 0.03\n",
      "Step [3200/10000], Loss: 0.2305, kappa: 0.84, epsilon_train: 0.03\n",
      "Step [3300/10000], Loss: 0.3878, kappa: 0.83, epsilon_train: 0.03\n",
      "Step [3400/10000], Loss: 0.2222, kappa: 0.83, epsilon_train: 0.03\n",
      "Step [3500/10000], Loss: 0.1216, kappa: 0.82, epsilon_train: 0.03\n",
      "Step [3600/10000], Loss: 0.1235, kappa: 0.82, epsilon_train: 0.04\n",
      "Step [3700/10000], Loss: 0.3393, kappa: 0.81, epsilon_train: 0.04\n",
      "Step [3800/10000], Loss: 0.2184, kappa: 0.81, epsilon_train: 0.04\n",
      "Step [3900/10000], Loss: 0.1204, kappa: 0.80, epsilon_train: 0.04\n",
      "Step [4000/10000], Loss: 0.1283, kappa: 0.80, epsilon_train: 0.04\n",
      "Step [4100/10000], Loss: 0.1133, kappa: 0.80, epsilon_train: 0.04\n",
      "Step [4200/10000], Loss: 0.1893, kappa: 0.79, epsilon_train: 0.04\n",
      "Step [4300/10000], Loss: 0.2297, kappa: 0.79, epsilon_train: 0.04\n",
      "Step [4400/10000], Loss: 0.1854, kappa: 0.78, epsilon_train: 0.04\n",
      "Step [4500/10000], Loss: 0.1971, kappa: 0.78, epsilon_train: 0.05\n",
      "Step [4600/10000], Loss: 0.1066, kappa: 0.77, epsilon_train: 0.05\n",
      "Step [4700/10000], Loss: 0.1292, kappa: 0.77, epsilon_train: 0.05\n",
      "Step [4800/10000], Loss: 0.2595, kappa: 0.76, epsilon_train: 0.05\n",
      "Step [4900/10000], Loss: 0.1914, kappa: 0.76, epsilon_train: 0.05\n",
      "Step [5000/10000], Loss: 0.1640, kappa: 0.75, epsilon_train: 0.05\n",
      "Step [5100/10000], Loss: 0.2299, kappa: 0.74, epsilon_train: 0.05\n",
      "Step [5200/10000], Loss: 0.2754, kappa: 0.74, epsilon_train: 0.05\n",
      "Step [5300/10000], Loss: 0.2071, kappa: 0.73, epsilon_train: 0.05\n",
      "Step [5400/10000], Loss: 0.2584, kappa: 0.73, epsilon_train: 0.05\n",
      "Step [5500/10000], Loss: 0.3176, kappa: 0.72, epsilon_train: 0.06\n",
      "Step [5600/10000], Loss: 0.2588, kappa: 0.72, epsilon_train: 0.06\n",
      "Step [5700/10000], Loss: 0.2433, kappa: 0.72, epsilon_train: 0.06\n",
      "Step [5800/10000], Loss: 0.1791, kappa: 0.71, epsilon_train: 0.06\n",
      "Step [5900/10000], Loss: 0.1908, kappa: 0.71, epsilon_train: 0.06\n",
      "Step [6000/10000], Loss: 0.2371, kappa: 0.70, epsilon_train: 0.06\n",
      "Step [6100/10000], Loss: 0.1335, kappa: 0.70, epsilon_train: 0.06\n",
      "Step [6200/10000], Loss: 0.2665, kappa: 0.69, epsilon_train: 0.06\n",
      "Step [6300/10000], Loss: 0.2173, kappa: 0.69, epsilon_train: 0.06\n",
      "Step [6400/10000], Loss: 0.1882, kappa: 0.68, epsilon_train: 0.06\n",
      "Step [6500/10000], Loss: 0.2014, kappa: 0.68, epsilon_train: 0.07\n",
      "Step [6600/10000], Loss: 0.1603, kappa: 0.67, epsilon_train: 0.07\n",
      "Step [6700/10000], Loss: 0.1840, kappa: 0.67, epsilon_train: 0.07\n",
      "Step [6800/10000], Loss: 0.1405, kappa: 0.66, epsilon_train: 0.07\n",
      "Step [6900/10000], Loss: 0.1799, kappa: 0.66, epsilon_train: 0.07\n",
      "Step [7000/10000], Loss: 0.2614, kappa: 0.65, epsilon_train: 0.07\n",
      "Step [7100/10000], Loss: 0.1459, kappa: 0.65, epsilon_train: 0.07\n",
      "Step [7200/10000], Loss: 0.2490, kappa: 0.64, epsilon_train: 0.07\n",
      "Step [7300/10000], Loss: 0.1756, kappa: 0.64, epsilon_train: 0.07\n",
      "Step [7400/10000], Loss: 0.3840, kappa: 0.63, epsilon_train: 0.07\n",
      "Step [7500/10000], Loss: 0.1788, kappa: 0.62, epsilon_train: 0.08\n",
      "Step [7600/10000], Loss: 0.2216, kappa: 0.62, epsilon_train: 0.08\n",
      "Step [7700/10000], Loss: 0.2723, kappa: 0.61, epsilon_train: 0.08\n",
      "Step [7800/10000], Loss: 0.1671, kappa: 0.61, epsilon_train: 0.08\n",
      "Step [7900/10000], Loss: 0.2712, kappa: 0.60, epsilon_train: 0.08\n",
      "Step [8000/10000], Loss: 0.2158, kappa: 0.60, epsilon_train: 0.08\n",
      "Step [8100/10000], Loss: 0.1877, kappa: 0.59, epsilon_train: 0.08\n",
      "Step [8200/10000], Loss: 0.1950, kappa: 0.59, epsilon_train: 0.08\n",
      "Step [8300/10000], Loss: 0.2977, kappa: 0.58, epsilon_train: 0.08\n",
      "Step [8400/10000], Loss: 0.1809, kappa: 0.58, epsilon_train: 0.08\n",
      "Step [8500/10000], Loss: 0.3204, kappa: 0.57, epsilon_train: 0.09\n",
      "Step [8600/10000], Loss: 0.2200, kappa: 0.57, epsilon_train: 0.09\n",
      "Step [8700/10000], Loss: 0.0759, kappa: 0.56, epsilon_train: 0.09\n",
      "Step [8800/10000], Loss: 0.2943, kappa: 0.56, epsilon_train: 0.09\n",
      "Step [8900/10000], Loss: 0.1208, kappa: 0.55, epsilon_train: 0.09\n",
      "Step [9000/10000], Loss: 0.1699, kappa: 0.55, epsilon_train: 0.09\n",
      "Step [9100/10000], Loss: 0.1438, kappa: 0.54, epsilon_train: 0.09\n",
      "Step [9200/10000], Loss: 0.2888, kappa: 0.54, epsilon_train: 0.09\n",
      "Step [9300/10000], Loss: 0.1765, kappa: 0.53, epsilon_train: 0.09\n",
      "Step [9400/10000], Loss: 0.2603, kappa: 0.53, epsilon_train: 0.09\n",
      "Step [9500/10000], Loss: 0.2084, kappa: 0.53, epsilon_train: 0.10\n",
      "Step [9600/10000], Loss: 0.2777, kappa: 0.52, epsilon_train: 0.10\n",
      "Step [9700/10000], Loss: 0.2303, kappa: 0.52, epsilon_train: 0.10\n",
      "Step [9800/10000], Loss: 0.2784, kappa: 0.51, epsilon_train: 0.10\n",
      "Step [9900/10000], Loss: 0.3065, kappa: 0.51, epsilon_train: 0.10\n",
      "Nominal Accuracy: 97.40%, Robust Accuracy: 16.33%\n",
      "Nominal Accuracy: 97.40%, Robust Accuracy: 78.79%\n"
     ]
    }
   ],
   "source": [
    "model = SimpleFCNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "train_with_pgd_and_ibp(model, optimizer, train_loader, total_steps=10000)\n",
    "test(model, test_loader, epsilon=0.01)\n",
    "test_with_pgd(model, test_loader, epsilon=0.1, alpha=0.01, iters=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TbIiP2sz9ea7"
   },
   "outputs": [],
   "source": [
    "# Interval propagation for IBP\n",
    "class IntervalPropagation:\n",
    "    def __init__(self, lower, upper):\n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return IntervalPropagation(self.lower + other, self.upper + other)\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, IntervalPropagation):\n",
    "            lower = torch.minimum(torch.minimum(self.lower * other.lower, self.lower * other.upper),\n",
    "                                  torch.minimum(self.upper * other.lower, self.upper * other.upper))\n",
    "            upper = torch.maximum(torch.maximum(self.lower * other.lower, self.lower * other.upper),\n",
    "                                  torch.maximum(self.upper * other.lower, self.upper * other.upper))\n",
    "            return IntervalPropagation(lower, upper)\n",
    "        else:\n",
    "            lower = torch.minimum(self.lower * other, self.upper * other)\n",
    "            upper = torch.maximum(self.lower * other, self.upper * other)\n",
    "            return IntervalPropagation(lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LfookCec_MqZ"
   },
   "outputs": [],
   "source": [
    "def propagate_layer(layer, interval):\n",
    "    interval_lower = interval.lower.view(interval.lower.size(0), -1)\n",
    "    interval_upper = interval.upper.view(interval.upper.size(0), -1)\n",
    "    new_lower = F.linear(interval_lower, layer.weight, layer.bias)\n",
    "    new_upper = F.linear(interval_upper, layer.weight, layer.bias)\n",
    "    return IntervalPropagation(new_lower, new_upper)\n",
    "\n",
    "def propagate_model(model, interval):\n",
    "    m1 = propagate_layer(model.fc1, interval)\n",
    "    m1_lower, m1_upper = relu_bounds(m1.lower, m1.upper)\n",
    "    m2 = propagate_layer(model.fc2, IntervalPropagation(m1_lower, m1_upper))\n",
    "    m2_lower, m2_upper = relu_bounds(m2.lower, m2.upper)\n",
    "    m3 = propagate_layer(model.fc3, IntervalPropagation(m2_lower, m2_upper))\n",
    "    return m3.lower, m3.upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kp7_Cpd9_O8C"
   },
   "outputs": [],
   "source": [
    "def schedule_lambda_reg(step, total_steps):\n",
    "    initial_lambda = 0.5\n",
    "    final_lambda = 0.8\n",
    "    return min(final_lambda, initial_lambda + (final_lambda - initial_lambda) * (step / total_steps))\n",
    "\n",
    "def hybrid_loss(logits, true_labels, logits_robust, logits_pgd, kappa, lambda_reg):\n",
    "    nominal_loss = F.cross_entropy(logits, true_labels)\n",
    "    robust_loss_ibp = F.cross_entropy(logits_robust, true_labels)\n",
    "    robust_loss_pgd = F.cross_entropy(logits_pgd, true_labels)\n",
    "    return kappa * nominal_loss + (1 - kappa) * (lambda_reg * robust_loss_ibp + (1 - lambda_reg) * robust_loss_pgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtaxiE8w_R3a"
   },
   "outputs": [],
   "source": [
    "\n",
    "def pgd_attack(model, images, labels, epsilon, alpha=0.005, iters=50):\n",
    "    adv_images = images.clone().detach().requires_grad_(True)\n",
    "    for i in range(iters):\n",
    "        outputs = model(adv_images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        adv_images = adv_images + alpha * adv_images.grad.sign()\n",
    "        eta = torch.clamp(adv_images - images, min=-epsilon, max=epsilon)\n",
    "        adv_images = torch.clamp(images + eta, min=0, max=1).detach_().requires_grad_(True)\n",
    "    return adv_images\n",
    "\n",
    "def train_with_pgd_and_ibp(model, optimizer, train_loader, total_steps, eps_target=0.1, pgd_alpha=0.005, pgd_iters=50):\n",
    "    model.train()\n",
    "    current_step = 0\n",
    "\n",
    "    while current_step < total_steps:\n",
    "        for images, labels in train_loader:\n",
    "            if current_step >= total_steps:\n",
    "                break\n",
    "            logits = model(images)\n",
    "            lower_logits, upper_logits = propagate_model(model, IntervalPropagation(images - eps_target, images + eps_target))\n",
    "            logits_robust = (lower_logits + upper_logits) / 2  # Middle point approximation\n",
    "            adv_images = pgd_attack(model, images, labels, epsilon=eps_target, alpha=pgd_alpha, iters=pgd_iters)\n",
    "            logits_pgd = model(adv_images)\n",
    "\n",
    "            kappa = max(0.5, 1 - current_step / total_steps)\n",
    "            lambda_reg = schedule_lambda_reg(current_step, total_steps)\n",
    "\n",
    "            loss = hybrid_loss(logits, labels, logits_robust, logits_pgd, kappa, lambda_reg)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if current_step % 100 == 0:\n",
    "                print(f\"Step [{current_step}/{total_steps}], Loss: {loss.item():.4f}, kappa: {kappa:.2f}, lambda_reg: {lambda_reg:.2f}\")\n",
    "\n",
    "            current_step += 1\n",
    "\n",
    "def test_verified_accuracy(model, test_loader, eps_values):\n",
    "    model.eval()\n",
    "    for eps in eps_values:\n",
    "        correct_verified = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                intervals = IntervalPropagation(images - eps, images + eps)\n",
    "\n",
    "                lower_logits, upper_logits = propagate_model(model, intervals)\n",
    "\n",
    "                logits_robust = lower_logits\n",
    "                _, pred_robust = logits_robust.max(1)\n",
    "                correct_verified += (pred_robust == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        verified_accuracy = correct_verified / total * 100\n",
    "        print(f\"Epsilon: {eps:.2f}, Verified Accuracy: {verified_accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "def test_with_pgd(model, test_loader, epsilon, alpha=0.005, iters=50):\n",
    "    model.eval()\n",
    "    correct_nominal = 0\n",
    "    correct_robust = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        with torch.no_grad():\n",
    "            logits = model(images)\n",
    "            _, pred = logits.max(1)\n",
    "            correct_nominal += (pred == labels).sum().item()\n",
    "        adv_images = pgd_attack(model, images, labels, epsilon, alpha, iters)\n",
    "        with torch.no_grad():\n",
    "            adv_logits = model(adv_images)\n",
    "            _, pred_robust = adv_logits.max(1)\n",
    "            correct_robust += (pred_robust == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    nominal_accuracy = correct_nominal / total * 100\n",
    "    robust_accuracy = correct_robust / total * 100\n",
    "    print(f\"Nominal Accuracy: {nominal_accuracy:.2f}%, Robust Accuracy: {robust_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25ZqK27X_fWx",
    "outputId": "701f1bb8-c1d9-4154-bbac-ffde1dc3cf4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/10000], Loss: 2.3129, kappa: 1.00, lambda_reg: 0.50\n",
      "Step [100/10000], Loss: 2.1594, kappa: 0.99, lambda_reg: 0.50\n",
      "Step [200/10000], Loss: 1.8446, kappa: 0.98, lambda_reg: 0.51\n",
      "Step [300/10000], Loss: 1.2791, kappa: 0.97, lambda_reg: 0.51\n",
      "Step [400/10000], Loss: 1.0290, kappa: 0.96, lambda_reg: 0.51\n",
      "Step [500/10000], Loss: 0.8263, kappa: 0.95, lambda_reg: 0.52\n",
      "Step [600/10000], Loss: 0.5789, kappa: 0.94, lambda_reg: 0.52\n",
      "Step [700/10000], Loss: 0.5429, kappa: 0.93, lambda_reg: 0.52\n",
      "Step [800/10000], Loss: 0.5969, kappa: 0.92, lambda_reg: 0.52\n",
      "Step [900/10000], Loss: 0.4983, kappa: 0.91, lambda_reg: 0.53\n",
      "Step [1000/10000], Loss: 0.5427, kappa: 0.90, lambda_reg: 0.53\n",
      "Step [1100/10000], Loss: 0.4120, kappa: 0.89, lambda_reg: 0.53\n",
      "Step [1200/10000], Loss: 0.4598, kappa: 0.88, lambda_reg: 0.54\n",
      "Step [1300/10000], Loss: 0.4892, kappa: 0.87, lambda_reg: 0.54\n",
      "Step [1400/10000], Loss: 0.6152, kappa: 0.86, lambda_reg: 0.54\n",
      "Step [1500/10000], Loss: 0.4374, kappa: 0.85, lambda_reg: 0.55\n",
      "Step [1600/10000], Loss: 0.4871, kappa: 0.84, lambda_reg: 0.55\n",
      "Step [1700/10000], Loss: 0.4156, kappa: 0.83, lambda_reg: 0.55\n",
      "Step [1800/10000], Loss: 0.4636, kappa: 0.82, lambda_reg: 0.55\n",
      "Step [1900/10000], Loss: 0.5108, kappa: 0.81, lambda_reg: 0.56\n",
      "Step [2000/10000], Loss: 0.4741, kappa: 0.80, lambda_reg: 0.56\n",
      "Step [2100/10000], Loss: 0.4039, kappa: 0.79, lambda_reg: 0.56\n",
      "Step [2200/10000], Loss: 0.6093, kappa: 0.78, lambda_reg: 0.57\n",
      "Step [2300/10000], Loss: 0.5155, kappa: 0.77, lambda_reg: 0.57\n",
      "Step [2400/10000], Loss: 0.4729, kappa: 0.76, lambda_reg: 0.57\n",
      "Step [2500/10000], Loss: 0.2362, kappa: 0.75, lambda_reg: 0.57\n",
      "Step [2600/10000], Loss: 0.4025, kappa: 0.74, lambda_reg: 0.58\n",
      "Step [2700/10000], Loss: 0.3119, kappa: 0.73, lambda_reg: 0.58\n",
      "Step [2800/10000], Loss: 0.3558, kappa: 0.72, lambda_reg: 0.58\n",
      "Step [2900/10000], Loss: 0.3641, kappa: 0.71, lambda_reg: 0.59\n",
      "Step [3000/10000], Loss: 0.4527, kappa: 0.70, lambda_reg: 0.59\n",
      "Step [3100/10000], Loss: 0.4174, kappa: 0.69, lambda_reg: 0.59\n",
      "Step [3200/10000], Loss: 0.4127, kappa: 0.68, lambda_reg: 0.60\n",
      "Step [3300/10000], Loss: 0.4974, kappa: 0.67, lambda_reg: 0.60\n",
      "Step [3400/10000], Loss: 0.3290, kappa: 0.66, lambda_reg: 0.60\n",
      "Step [3500/10000], Loss: 0.6196, kappa: 0.65, lambda_reg: 0.60\n",
      "Step [3600/10000], Loss: 0.5170, kappa: 0.64, lambda_reg: 0.61\n",
      "Step [3700/10000], Loss: 0.4676, kappa: 0.63, lambda_reg: 0.61\n",
      "Step [3800/10000], Loss: 0.3656, kappa: 0.62, lambda_reg: 0.61\n",
      "Step [3900/10000], Loss: 0.3675, kappa: 0.61, lambda_reg: 0.62\n",
      "Step [4000/10000], Loss: 0.3619, kappa: 0.60, lambda_reg: 0.62\n",
      "Step [4100/10000], Loss: 0.3210, kappa: 0.59, lambda_reg: 0.62\n",
      "Step [4200/10000], Loss: 0.3753, kappa: 0.58, lambda_reg: 0.63\n",
      "Step [4300/10000], Loss: 0.4615, kappa: 0.57, lambda_reg: 0.63\n",
      "Step [4400/10000], Loss: 0.3466, kappa: 0.56, lambda_reg: 0.63\n",
      "Step [4500/10000], Loss: 0.3834, kappa: 0.55, lambda_reg: 0.64\n",
      "Step [4600/10000], Loss: 0.4114, kappa: 0.54, lambda_reg: 0.64\n",
      "Step [4700/10000], Loss: 0.3772, kappa: 0.53, lambda_reg: 0.64\n",
      "Step [4800/10000], Loss: 0.5431, kappa: 0.52, lambda_reg: 0.64\n",
      "Step [4900/10000], Loss: 0.6130, kappa: 0.51, lambda_reg: 0.65\n",
      "Step [5000/10000], Loss: 0.4579, kappa: 0.50, lambda_reg: 0.65\n",
      "Step [5100/10000], Loss: 0.4017, kappa: 0.50, lambda_reg: 0.65\n",
      "Step [5200/10000], Loss: 0.6125, kappa: 0.50, lambda_reg: 0.66\n",
      "Step [5300/10000], Loss: 0.2866, kappa: 0.50, lambda_reg: 0.66\n",
      "Step [5400/10000], Loss: 0.3079, kappa: 0.50, lambda_reg: 0.66\n",
      "Step [5500/10000], Loss: 0.3309, kappa: 0.50, lambda_reg: 0.67\n",
      "Step [5600/10000], Loss: 0.3793, kappa: 0.50, lambda_reg: 0.67\n",
      "Step [5700/10000], Loss: 0.5298, kappa: 0.50, lambda_reg: 0.67\n",
      "Step [5800/10000], Loss: 0.3553, kappa: 0.50, lambda_reg: 0.67\n",
      "Step [5900/10000], Loss: 0.4699, kappa: 0.50, lambda_reg: 0.68\n",
      "Step [6000/10000], Loss: 0.7197, kappa: 0.50, lambda_reg: 0.68\n",
      "Step [6100/10000], Loss: 0.4346, kappa: 0.50, lambda_reg: 0.68\n",
      "Step [6200/10000], Loss: 0.3151, kappa: 0.50, lambda_reg: 0.69\n",
      "Step [6300/10000], Loss: 0.3568, kappa: 0.50, lambda_reg: 0.69\n",
      "Step [6400/10000], Loss: 0.5614, kappa: 0.50, lambda_reg: 0.69\n",
      "Step [6500/10000], Loss: 0.5044, kappa: 0.50, lambda_reg: 0.70\n",
      "Step [6600/10000], Loss: 0.2855, kappa: 0.50, lambda_reg: 0.70\n",
      "Step [6700/10000], Loss: 0.2951, kappa: 0.50, lambda_reg: 0.70\n",
      "Step [6800/10000], Loss: 0.4857, kappa: 0.50, lambda_reg: 0.70\n",
      "Step [6900/10000], Loss: 0.3082, kappa: 0.50, lambda_reg: 0.71\n",
      "Step [7000/10000], Loss: 0.3305, kappa: 0.50, lambda_reg: 0.71\n",
      "Step [7100/10000], Loss: 0.2337, kappa: 0.50, lambda_reg: 0.71\n",
      "Step [7200/10000], Loss: 0.2957, kappa: 0.50, lambda_reg: 0.72\n",
      "Step [7300/10000], Loss: 0.4470, kappa: 0.50, lambda_reg: 0.72\n",
      "Step [7400/10000], Loss: 0.3388, kappa: 0.50, lambda_reg: 0.72\n",
      "Step [7500/10000], Loss: 0.2351, kappa: 0.50, lambda_reg: 0.73\n",
      "Step [7600/10000], Loss: 0.3895, kappa: 0.50, lambda_reg: 0.73\n",
      "Step [7700/10000], Loss: 0.5047, kappa: 0.50, lambda_reg: 0.73\n",
      "Step [7800/10000], Loss: 0.2831, kappa: 0.50, lambda_reg: 0.73\n",
      "Step [7900/10000], Loss: 0.4047, kappa: 0.50, lambda_reg: 0.74\n",
      "Step [8000/10000], Loss: 0.5107, kappa: 0.50, lambda_reg: 0.74\n",
      "Step [8100/10000], Loss: 0.3576, kappa: 0.50, lambda_reg: 0.74\n",
      "Step [8200/10000], Loss: 0.2173, kappa: 0.50, lambda_reg: 0.75\n",
      "Step [8300/10000], Loss: 0.3484, kappa: 0.50, lambda_reg: 0.75\n",
      "Step [8400/10000], Loss: 0.4900, kappa: 0.50, lambda_reg: 0.75\n",
      "Step [8500/10000], Loss: 0.5255, kappa: 0.50, lambda_reg: 0.76\n",
      "Step [8600/10000], Loss: 0.3635, kappa: 0.50, lambda_reg: 0.76\n",
      "Step [8700/10000], Loss: 0.3792, kappa: 0.50, lambda_reg: 0.76\n",
      "Step [8800/10000], Loss: 0.2862, kappa: 0.50, lambda_reg: 0.76\n",
      "Step [8900/10000], Loss: 0.2589, kappa: 0.50, lambda_reg: 0.77\n",
      "Step [9000/10000], Loss: 0.2879, kappa: 0.50, lambda_reg: 0.77\n",
      "Step [9100/10000], Loss: 0.3960, kappa: 0.50, lambda_reg: 0.77\n",
      "Step [9200/10000], Loss: 0.2283, kappa: 0.50, lambda_reg: 0.78\n",
      "Step [9300/10000], Loss: 0.2764, kappa: 0.50, lambda_reg: 0.78\n",
      "Step [9400/10000], Loss: 0.2544, kappa: 0.50, lambda_reg: 0.78\n",
      "Step [9500/10000], Loss: 0.3285, kappa: 0.50, lambda_reg: 0.79\n",
      "Step [9600/10000], Loss: 0.2918, kappa: 0.50, lambda_reg: 0.79\n",
      "Step [9700/10000], Loss: 0.2655, kappa: 0.50, lambda_reg: 0.79\n",
      "Step [9800/10000], Loss: 0.2416, kappa: 0.50, lambda_reg: 0.79\n",
      "Step [9900/10000], Loss: 0.3068, kappa: 0.50, lambda_reg: 0.80\n",
      "\n",
      "Test: Model verified accuracy across different epsilons\n",
      "Epsilon: 0.01, Verified Accuracy: 94.04%\n",
      "Epsilon: 0.02, Verified Accuracy: 93.93%\n",
      "Epsilon: 0.03, Verified Accuracy: 93.90%\n",
      "Epsilon: 0.04, Verified Accuracy: 93.76%\n",
      "Epsilon: 0.05, Verified Accuracy: 93.68%\n",
      "Epsilon: 0.06, Verified Accuracy: 93.51%\n",
      "Epsilon: 0.07, Verified Accuracy: 93.40%\n",
      "Epsilon: 0.08, Verified Accuracy: 93.27%\n",
      "Epsilon: 0.09, Verified Accuracy: 93.00%\n",
      "Epsilon: 0.10, Verified Accuracy: 92.84%\n",
      "\n",
      "Test: Model with PGD adversarial examples\n",
      "Nominal Accuracy: 94.00%, Robust Accuracy: 63.44%\n"
     ]
    }
   ],
   "source": [
    "model = SimpleFCNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "total_steps = 10000\n",
    "eps_target = 0.1\n",
    "pgd_alpha = 0.005\n",
    "pgd_iters = 50\n",
    "\n",
    "# Training the model\n",
    "train_with_pgd_and_ibp(model, optimizer, train_loader, total_steps=total_steps, eps_target=eps_target, pgd_alpha=pgd_alpha, pgd_iters=pgd_iters)\n",
    "\n",
    "# Testing verified accuracy across different epsilon values\n",
    "eps_values = np.linspace(0.01, 0.1, 10)\n",
    "print(\"\\nTest: Model verified accuracy across different epsilons\")\n",
    "test_verified_accuracy(model, test_loader, eps_values)\n",
    "\n",
    "# Testing robust accuracy with PGD adversarial examples\n",
    "print(\"\\nTest: Model with PGD adversarial examples\")\n",
    "test_with_pgd(model, test_loader, epsilon=0.1, alpha=0.005, iters=50)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
