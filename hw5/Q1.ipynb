{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWZRTXd4YFMx",
        "outputId": "7e935971-38df-451f-ec6a-154932a05b44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/uiuc-focal-lab/syncode.git@main\n",
            "  Cloning https://github.com/uiuc-focal-lab/syncode.git (to revision main) to /tmp/pip-req-build-pkuxou3q\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/uiuc-focal-lab/syncode.git /tmp/pip-req-build-pkuxou3q\n",
            "  Resolved https://github.com/uiuc-focal-lab/syncode.git to commit 5ec58cd2a34effa4196c6ed13e73f0480bbf45f3\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mxeval@ git+https://github.com/shubhamugare/mxeval.git (from syncode==0.1)\n",
            "  Cloning https://github.com/shubhamugare/mxeval.git to /tmp/pip-install-308v1qrf/mxeval_915895943925457391c0791adab68002\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/shubhamugare/mxeval.git /tmp/pip-install-308v1qrf/mxeval_915895943925457391c0791adab68002\n",
            "  Resolved https://github.com/shubhamugare/mxeval.git to commit 590129d063c5e7d145e8b15a83f00ff20d69a189\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fire (from syncode==0.1)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting interegular (from syncode==0.1)\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Collecting regex==2023.8.8 (from syncode==0.1)\n",
            "  Downloading regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from syncode==0.1) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from syncode==0.1) (4.66.6)\n",
            "Collecting transformers==4.44.0 (from syncode==0.1)\n",
            "  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from syncode==0.1)\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from syncode==0.1) (4.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0->syncode==0.1) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0->syncode==0.1) (0.26.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0->syncode==0.1) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0->syncode==0.1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0->syncode==0.1) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0->syncode==0.1) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0->syncode==0.1) (0.4.5)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.0->syncode==0.1)\n",
            "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->syncode==0.1) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->syncode==0.1)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->syncode==0.1) (2.2.2)\n",
            "Collecting xxhash (from datasets->syncode==0.1)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->syncode==0.1)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->syncode==0.1)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->syncode==0.1) (3.11.10)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->syncode==0.1) (2.5.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->syncode==0.1) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->syncode==0.1) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->syncode==0.1) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->syncode==0.1) (0.22.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->syncode==0.1) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->syncode==0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->syncode==0.1) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->syncode==0.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->syncode==0.1) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->syncode==0.1) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->syncode==0.1) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->syncode==0.1) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->syncode==0.1) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->syncode==0.1) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->syncode==0.1) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->syncode==0.1) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.0->syncode==0.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.0->syncode==0.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.0->syncode==0.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.0->syncode==0.1) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->syncode==0.1) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->syncode==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->syncode==0.1) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->syncode==0.1) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->syncode==0.1) (1.17.0)\n",
            "Downloading regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m771.9/771.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.44.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: syncode, fire, mxeval\n",
            "  Building wheel for syncode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for syncode: filename=syncode-0.1-py3-none-any.whl size=217942 sha256=670dc06da1b62fa9b5a8d25272332a77562994b9aef84c7f83061cd83e64ba2a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uhe24g2y/wheels/23/90/83/45dbed3a023e4d9654d8ecec0caff33948beedeb04fdeed331\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=2cec4154a81f88b22adf7a3a8d4d4cbfc23e9418ff3dca1539665cdad9486bfa\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "  Building wheel for mxeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mxeval: filename=mxeval-1.0-py3-none-any.whl size=4426397 sha256=258b3d76e1f2095efd310a16846d058e2b83c7d0162680cb9a5799d40c4bea1f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uhe24g2y/wheels/3e/f5/a5/764e23ecae9b1b6d851d346ff94626f6c90e2ebdf1625b9617\n",
            "Successfully built syncode fire mxeval\n",
            "Installing collected packages: xxhash, regex, interegular, fsspec, fire, dill, mxeval, multiprocess, tokenizers, transformers, datasets, syncode\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.9.11\n",
            "    Uninstalling regex-2024.9.11:\n",
            "      Successfully uninstalled regex-2024.9.11\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.46.3\n",
            "    Uninstalling transformers-4.46.3:\n",
            "      Successfully uninstalled transformers-4.46.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fire-0.7.0 fsspec-2024.9.0 interegular-0.3.3 multiprocess-0.70.16 mxeval-1.0 regex-2023.8.8 syncode-0.1 tokenizers-0.19.1 transformers-4.44.0 xxhash-3.5.0\n",
            "Collecting lark-parser\n",
            "  Downloading lark_parser-0.12.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading lark_parser-0.12.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lark-parser\n",
            "Successfully installed lark-parser-0.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/uiuc-focal-lab/syncode.git@main\n",
        "!pip install lark-parser"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from syncode import Syncode\n",
        "from transformers import AutoTokenizer\n",
        "os.environ[\"HF_TOKEN\"] = \"\"\n",
        "!huggingface-cli login --token $HF_TOKEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhyhxGwvcRSm",
        "outputId": "48caed95-6953-4f74-f7f1-ed644eabba5d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "The token `llama-2-7b` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arithmetic_grammar = r\"\"\"\n",
        "start: \"{\" WS \"\\\"\" \"operands\" \"\\\"\" WS \":\" WS \"[\" WS float WS \",\" WS float WS \"]\" WS \",\" WS \"\\\"\" \"operator\" \"\\\"\" WS \":\" WS operator WS \"}\"\n",
        "\n",
        "float: /[0-9]+(\\.[0-9]+)?/\n",
        "\n",
        "operator: \"+\" | \"-\" | \"*\" | \"/\"\n",
        "\n",
        "WS: /[ \\t\\n\\r]+/\n",
        "\n",
        "%ignore WS\n",
        "\"\"\"\n",
        "\n",
        "few_shot_prompt = \"\"\"Below are examples of extracting two floating point operands and the operator from a user query.\n",
        "Do not compute the result here. Produce ONLY the JSON object corresponding to the given user query.\n",
        "DO NOT print additional queries or lines after the JSON. DO NOT print 'Extraction:' prefix. Just the JSON.\n",
        "\n",
        "Example 1:\n",
        "Query: \"What is 15.5 times 3.0?\"\n",
        "{\"operands\": [15.5, 3.0], \"operator\": \"*\"}\n",
        "\n",
        "Example 2:\n",
        "Query: \"What is 100.25 minus 50.75?\"\n",
        "{\"operands\": [100.25, 50.75], \"operator\": \"-\"}\n",
        "\n",
        "Example 3:\n",
        "Query: \"What is 200.0 divided by 8.0?\"\n",
        "{\"operands\": [200.0, 8.0], \"operator\": \"/\"}\n",
        "\n",
        "Follow the exact format shown in examples.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "JLA4ODDyaCPs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"meta-llama/Llama-3.2-1B\"\n",
        "\n",
        "def run_syncode(query: str):\n",
        "    prompt = few_shot_prompt + \"\\nQuery: \\\"\" + query.strip() + \"\\\"\\n\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    syn_llm = Syncode(\n",
        "        model=model_name,\n",
        "        grammar=arithmetic_grammar,\n",
        "        parse_output_only=True,\n",
        "        max_new_tokens=200,\n",
        "        mode='grammar_mask',\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        do_sample=False,\n",
        "        temperature=0.0,\n",
        "    )\n",
        "\n",
        "    extraction = syn_llm.infer(prompt)[0].strip()\n",
        "    print(\"Raw Extraction:\", extraction)\n",
        "\n",
        "    match = re.search(r\"\\{.*?\\}\", extraction)\n",
        "    if match:\n",
        "        extraction = match.group(0)\n",
        "    else:\n",
        "        raise ValueError(\"No valid JSON object found in the output.\")\n",
        "\n",
        "    data = json.loads(extraction)\n",
        "\n",
        "    operands = data[\"operands\"]\n",
        "    operator = data[\"operator\"]\n",
        "\n",
        "    op1, op2 = map(float, operands)\n",
        "    if operator == \"+\":\n",
        "        result = op1 + op2\n",
        "    elif operator == \"-\":\n",
        "        result = op1 - op2\n",
        "    elif operator == \"*\":\n",
        "        result = op1 * op2\n",
        "    elif operator == \"/\":\n",
        "        result = op1 / op2\n",
        "    else:\n",
        "        raise ValueError(\"Invalid operator encountered.\")\n",
        "\n",
        "    return (operands, operator, result)"
      ],
      "metadata": {
        "id": "O7AbRAxMkQzL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_test_cases(test_cases):\n",
        "    print(\"Running test cases:\\n\")\n",
        "    for i, query in enumerate(test_cases, 1):\n",
        "        print(f\"Test Case {i}:\")\n",
        "        try:\n",
        "            operands, operator, answer = run_syncode(query)\n",
        "            print(f\"Operands: {operands}\")\n",
        "            print(f\"Operator: {operator}\")\n",
        "            print(f\"Final Answer: {answer}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {str(e)}\")\n",
        "        print()"
      ],
      "metadata": {
        "id": "sFrLBPsPlHUH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_queries = [\n",
        "    \"What is 327. multiplied by 11.0?\",\n",
        "    \"What is 45.1 plus 23.54?\",\n",
        "    \"What is 120.4 divided by 4.0?\"\n",
        "]\n",
        "\n",
        "run_test_cases(test_queries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_wBdvzbj-bi",
        "outputId": "f0fd1e67-9e2c-48ac-cd13-3b3a037481cd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running test cases:\n",
            "\n",
            "Test Case 1:\n",
            "Raw Extraction: { \"operands\": [327.0, 11.0], \"operator\": \"*\" }\n",
            "\n",
            "Query: \"What is 100.0 divided by 2.0?\"\n",
            "{ \"operands\": [100.0, 2.0], \"operator\": \"/\" }\n",
            "\n",
            "Query: \"What is 100.0 divided by 2.0?\"\n",
            "{ \"operands\": [100.0, 2.0], \"operator\": \"/\" }\n",
            "\n",
            "Query: \"What is 100.0 divided by 2.0?\"\n",
            "{ \"operands\": [100.0, 2.0], \"operator\": \"/\" }\n",
            "\n",
            "Query: \"What is 100.0 divided by 2.0?\"\n",
            "{ \"operands\": [100.0, 2.0], \"operator\": \"/\" }\n",
            "\n",
            "Query: \"What is 100.0 divided by 2.0?\"\n",
            "{ \"operands\": [100.0, 2.0], \"operator\": \"/\" }\n",
            "\n",
            "Query: \"What is\n",
            "Operands: [327.0, 11.0]\n",
            "Operator: *\n",
            "Final Answer: 3597.0\n",
            "\n",
            "Test Case 2:\n",
            "Raw Extraction: { \"operands\": [45.1, 23.54], \"operator\": \"+\" }\n",
            "\n",
            "Query: \"What is 100.25 minus 50.75?\"\n",
            "{ \"operands\": [100.25, 50.75], \"operator\": \"-\" }\n",
            "\n",
            "Query: \"What is 200.0 divided by 8.0?\"\n",
            "{ \"operands\": [200.0, 8.0], \"operator\": \"/\" }\n",
            "\n",
            "Query: \"What is 15.5 times 3.0?\"\n",
            "{ \"operands\": [15.5, 3.0], \"operator\": \"*\" }\n",
            "\n",
            "Query: \"What is 100.25 minus 50.75?\"\n",
            "{ \"operands\": [100.25, 50.75], \"operator\": \"-\" }\n",
            "\n",
            "Query: \"What is 200.0 divided by 8.0?\"\n",
            "{ \"operands\": [200.0, 8.0], \"operator\": \"/\" }\n",
            "\n",
            "Query: \"What is 45.1\n",
            "Operands: [45.1, 23.54]\n",
            "Operator: +\n",
            "Final Answer: 68.64\n",
            "\n",
            "Test Case 3:\n",
            "Raw Extraction: { \"operands\": [120.4, 4.0], \"operator\": \"/\" }\n",
            "\n",
            "Query: \"What is 100.0 times 2.0?\"\n",
            "{ \"operands\": [100.0, 2.0], \"operator\": \"*\" }\n",
            "\n",
            "Query: \"What is 100.0 divided by 2.0?\"\n",
            "{ \"operands\": [100.0, 2.0], \"operator\": \"/\" }\n",
            "\n",
            "Query: \"What is 100.0 minus 2.0?\"\n",
            "{ \"operands\": [100.0, 2.0], \"operator\": \"-\" }\n",
            "\n",
            "Query: \"What is 100.0 plus 2.0?\"\n",
            "{ \"operands\": [100.0, 2.0], \"operator\": \"+\" }\n",
            "\n",
            "Query: \"What is 100.0 times 2.0 plus 2.0?\"\n",
            "{ \"operands\": [100.0, 2.0], \"operator\": \"*\" }\n",
            "\n",
            "Query: \"What is\n",
            "Operands: [120.4, 4.0]\n",
            "Operator: /\n",
            "Final Answer: 30.1\n",
            "\n"
          ]
        }
      ]
    }
  ]
}